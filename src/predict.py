import torch
import cv2
import shutil
import numpy as np
from pathlib import Path
from tqdm import tqdm
from ai_model import SRResNet
import config as cfg

def process_tiled(model, img, device, tile_size=256, overlap=16):
    """
    Przetwarza obraz kafelkami z zak≈ÇadkƒÖ (overlap), aby usunƒÖƒá linie ≈ÇƒÖczenia.
    Obs≈Çuguje du≈ºe obrazy bez wywalania b≈Çƒôdu pamiƒôci (OOM).
    """
    h, w, c = img.shape
    
    # 1. Padding do wielokrotno≈õci tile_size
    pad_h = (tile_size - h % tile_size) % tile_size
    pad_w = (tile_size - w % tile_size) % tile_size
    
    # Dodajemy padding do oryginalnego rozmiaru (odbicie lustrzane krawƒôdzi)
    img_padded = cv2.copyMakeBorder(img, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT)
    
    # 2. Dodajemy DODATKOWY padding na overlap (zak≈Çadkƒô) dooko≈Ça ca≈Çego obrazu
    img_padded = cv2.copyMakeBorder(img_padded, overlap, overlap, overlap, overlap, cv2.BORDER_REFLECT)
    
    h_pad, w_pad, _ = img_padded.shape
    
    # Pusty obraz wynikowy (rozmiar jak po pierwszym paddingu, bez overlap)
    result_h = h + pad_h
    result_w = w + pad_w
    result = np.zeros((result_h, result_w, c), dtype=np.uint8)
    
    # 3. Iteracja po kafelkach
    # U≈ºywamy torch.no_grad() tutaj, ≈ºeby nie trzymaƒá grafu oblicze≈Ñ w pamiƒôci
    with torch.no_grad():
        for y in range(0, result_h, tile_size):
            for x in range(0, result_w, tile_size):
                
                # Wycinamy kafelek wej≈õciowy (wiƒôkszy o 2*overlap)
                tile_in = img_padded[y : y + tile_size + 2*overlap, 
                                     x : x + tile_size + 2*overlap]
                
                # --- PRZETWARZANIE AI ---
                inp = cv2.cvtColor(tile_in, cv2.COLOR_BGR2RGB)
                inp_tensor = torch.from_numpy(inp).permute(2, 0, 1).float() / 255.0
                inp_tensor = inp_tensor.unsqueeze(0).to(device)
                
                out_tensor = model(inp_tensor)
                    
                out = out_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()
                out = np.clip(out * 255, 0, 255).astype(np.uint8)
                out = cv2.cvtColor(out, cv2.COLOR_RGB2BGR)
                # ------------------------
                
                # 4. Wycinanie ≈õrodka (usuwanie brzeg√≥w z b≈Çƒôdami/overlapem)
                tile_out = out[overlap : -overlap, overlap : -overlap]
                
                # Wklejamy czysty ≈õrodek do wyniku
                # Zabezpieczenie wymiar√≥w (na wypadek krawƒôdzi)
                th, tw = tile_out.shape[:2]
                h_end = min(y + th, result_h)
                w_end = min(x + tw, result_w)
                
                result[y:h_end, x:w_end] = tile_out[:h_end-y, :w_end-x]

    # 5. Przyciƒôcie do oryginalnego rozmiaru (usuwamy padding z kroku 1)
    return result[:h, :w]

def run_prediction(task_name):
    # Wykrywanie urzƒÖdzenia (zgodnie z configiem lub auto)
    if hasattr(cfg, 'DEVICE'):
        device = cfg.DEVICE
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    print(f"\nüîÆ GENEROWANIE WYNIK√ìW AI (SRResNet): {task_name.upper()}")
    print(f"   UrzƒÖdzenie: {device}")
    
    # ≈Åadowanie modelu
    model = SRResNet().to(device)
    path = cfg.MODELS_DIR / f'model_{task_name}.pth'
    
    if not path.exists():
        print(f"‚ùå Nie znaleziono modelu: {path}")
        print("   Najpierw uruchom trening (Opcja 3).")
        return

    try:
        model.load_state_dict(torch.load(path, map_location=device))
        model.eval()
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd ≈Çadowania wag: {e}")
        return
        
    # Przygotowanie folder√≥w
    out_dir = cfg.RESULTS_DIR / 'ai' / task_name
    if out_dir.exists(): shutil.rmtree(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # Pobranie listy plik√≥w
    input_dir = cfg.PROCESSED_DIR / task_name
    files = list(input_dir.glob('*'))
    
    if not files:
        print(f"‚ö†Ô∏è Brak plik√≥w w {input_dir}. Uruchom najpierw generator danych (Opcja 1).")
        return

    # Pƒôtla przetwarzania
    for f in tqdm(files, desc="Przetwarzanie"):
        img = cv2.imread(str(f))
        if img is None: continue
        
        # --- FIX: Obs≈Çuga obraz√≥w czarno-bia≈Çych ---
        if len(img.shape) == 2:
            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        
        # --- LOGIKA LOW_RES (Zgodna z train.py) ---
        # Model SRResNet (VDSR) oczekuje na wej≈õciu obrazu ju≈º powiƒôkszonego,
        # ≈ºeby m√≥c dodaƒá do niego detale (skip connection).
        if task_name == 'low_res':
            h, w = img.shape[:2]
            img = cv2.resize(img, (w * cfg.SCALE_FACTOR, h * cfg.SCALE_FACTOR), interpolation=cv2.INTER_CUBIC)

        # --- INFERENCE Z ZABEZPIECZENIEM PAMIƒòCI ---
        try:
            # Domy≈õlne ustawienia: kafelki 256px, zak≈Çadka 16px
            res = process_tiled(model, img, device, tile_size=256, overlap=16)
            cv2.imwrite(str(out_dir / f.name), res)
            
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"‚ö†Ô∏è OOM na GPU dla {f.name}, prze≈ÇƒÖczam na CPU...")
                torch.cuda.empty_cache()
                
                # Przenosimy model na CPU tymczasowo
                model_cpu = model.to('cpu')
                res = process_tiled(model_cpu, img, 'cpu', tile_size=128, overlap=16)
                cv2.imwrite(str(out_dir / f.name), res)
                
                # Wracamy na GPU
                model.to(device)
            else:
                print(f"‚ùå Nieoczekiwany b≈ÇƒÖd dla {f.name}: {e}")

if __name__ == "__main__":
    # Testowe uruchomienie
    run_prediction('noise')